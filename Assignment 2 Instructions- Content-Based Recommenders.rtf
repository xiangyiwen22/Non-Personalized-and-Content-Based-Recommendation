{\rtf1\ansi\ansicpg1252\cocoartf1671\cocoasubrtf600
{\fonttbl\f0\fswiss\fcharset0 ArialMT;}
{\colortbl;\red255\green255\blue255;\red24\green24\blue24;\red255\green255\blue255;\red53\green118\blue190;
}
{\*\expandedcolortbl;;\cssrgb\c12157\c12157\c12157;\cssrgb\c100000\c100000\c100000;\cssrgb\c25882\c54510\c79216;
}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid1}
{\list\listtemplateid2\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}.}{\leveltext\leveltemplateid101\'02\'00.;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid2}
{\list\listtemplateid3\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid201\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid3}
{\list\listtemplateid4\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid301\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid4}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}{\listoverride\listid2\listoverridecount0\ls2}{\listoverride\listid3\listoverridecount0\ls3}{\listoverride\listid4\listoverridecount0\ls4}}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\sl720\sa400\partightenfactor0

\f0\fs64 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Assignment 2 Instructions: Content-Based Recommenders\
\pard\pardeftab720\sl480\sa320\partightenfactor0

\fs44 \cf2 Overview\
\pard\pardeftab720\sl420\sa400\partightenfactor0

\fs28 \cf2 In this assignment, you will hand-create and use some content-based profiles. You\'92ll go through a set of variations to see how certain features of the computation can introduce (or reduce) biases.\
\pard\pardeftab720\sl480\sa320\partightenfactor0

\fs44 \cf2 Instructions\
\pard\pardeftab720\sl480\sa240\partightenfactor0

\fs32 \cf2 The Data Set\
\pard\pardeftab720\sl420\sa400\partightenfactor0

\fs28 \cf2 First, download the Assignment 2 dataset ({\field{\*\fldinst{HYPERLINK "https://d396qusza40orc.cloudfront.net/flex-umntestsite/on-demand_files/Assignment%202.xls"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 linked here as a spreadsheet}}). It contains a table of content attributes for 20 documents across 10 attributes. It also lists two users\'92 evaluations of five documents each. For purposes of this assignment, we\'92re treating content attributes as boolean (either an article is about a topic or it isn\'92t) and we\'92re treating evaluations as positive (liked it), negative (disliked it), or unknown (never saw it).\
\pard\pardeftab720\sl480\sa320\partightenfactor0

\fs44 \cf2 Part 1. Build and use a very basic profile\
\pard\pardeftab720\sl420\sa400\partightenfactor0

\fs28 \cf2 First, you will build a very simple profile of user preferences for attributes. In this profile, you\'92ll count the total the number of positive and negative evaluations associated with each attribute, and create a profile with the total score for each attribute for each user. For example, user 1\'92s score for \'93Family\'94 will get a +1 from doc1 (positive evaluation) and a -1 from doc 19 (negative evaluation) for a total profile value of 0 (neutral). In contrast, user 2\'92s score for Europe will be +3 (+1 each for doc2, doc4, and doc17).\
You can compute the profiles and place them in the \'93User Profiles\'94 section of the spreadsheet.\
Now compute the predicted score for each user for each document (a simple dot-product). Type in the answers to the following questions (answers may include already-rated articles) as part of the Quiz:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl320\sa200\partightenfactor0
\ls1\ilvl0\cf2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Which document does the simple profile predict user 1 will like best?\cb1 \
\ls1\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 What score does that prediction get?\cb1 \
\ls1\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 How many documents does the model predict user 2 will dislike (prediction score that is negative)?\cb1 \
\pard\pardeftab720\sl420\sa400\partightenfactor0
\cf2 \cb3 Notice that this model is consistent with the users\'92 ratings -- it predicts liking for all the positive documents and disliking for all the negative ones.\
\pard\pardeftab720\sl480\sa320\partightenfactor0

\fs44 \cf2 Part 2. Next, let\'92s treat all articles as having unit weight ...\
\pard\pardeftab720\sl420\sa400\partightenfactor0

\fs28 \cf2 You may have noticed that in our computation an article that had many attributes checked could have more influence on the overall profile than one that had only a few. doc 1 and doc 19 each have five attributes, while doc6, doc7, and doc18 only have 2 attributes each.\
We want to explore whether our simple model may be counting these attribute-heavy documents too much. For example, we might conclude that liking doc6 says more about liking baseball (since it is one of only two attributes for the article along with Europe) than liking doc1 says (since doc1 is also about politics, Asia, soccer, and family).\
To try this out, make a copy of the attributes matrix on another sheet. Then we\'92re going to have you normalize each row to be a unit length vector. We can do this in two steps:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl320\sa200\partightenfactor0
\ls2\ilvl0\cf2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1.	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Count the total number of items in the row (you can do this via SUM or COUNT function).\cb1 \
\ls2\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2.	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Divide each value by the square root of that number of items. If you do this right, doc1\'92s values will all change from 1 to 0.447214 (approx). Documents with 4 attributes will change to 0.5 (since 4 * .5^2 = 1), and so forth. Remember, don\'92t have the SUM or COUNT depend on the copy of the cells you\'92re changing or you\'92ll get a circular dependency. Have your new sheet depend on values on your old sheet.\cb1 \
\pard\pardeftab720\sl420\sa400\partightenfactor0
\cf2 \cb3 Once you have the new values, compute your second set of user profiles and new predictions. If you did this right, you\'92ll see a prediction of 1.0090 (approx) for user1/doc1. Don\'92t worry about the scale of the numbers (they\'92ll all be smaller, in absolute value terms), but look at the order of them.\
This time we\'92ll start with user2. With our simple profile, doc7 and doc19 both had similar \'93like\'94 predictions (+2 each). Now they don\'92t. Let's see what values are predicted for the second model:\
doc7: 0.7444 (plus or minus 0.01)\
doc 19: 0.4834 (plus or minus 0.01)\
The difference here can be seen by looking at the profile attribute values. Doc7 is 50% about one of user2\'92s favorite topics (security) which is now more heavily emphasized).\
Now let\'92s look at user 1. While user 1's first-place document is the same in both models, that isn't true for other places. In our simple model, the second/third place recommendation was a tie between doc1 and doc 12. Neither of those is in second place with this new model.\
Type in the answers to the following questions as part of the Quiz:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl320\sa200\partightenfactor0
\ls3\ilvl0\cf2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Which document is now in second with this new model?\cb1 \
\ls3\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 What prediction score does it have?\cb1 \
\pard\pardeftab720\sl480\sa320\partightenfactor0

\fs44 \cf2 \cb3 Part 3. Finally, let\'92s consider how common different terms are among our documents \'85\
\pard\pardeftab720\sl420\sa400\partightenfactor0

\fs28 \cf2 We\'92re going to do one more model -- one that accounts for the fact the the content attributes have vastly different frequencies.\
We\'92re going to include an IDF (inverse document frequency) term into our equation. Start with your spreadsheet from part 2. Add a row that shows 1/DF where DF is the number of documents in which each content attribute occurs. For example, baseball occurs in 4 documents, so baseball\'92s entry will be 0.25. Politics occurs in 10 documents, so it will get an IDF score of 0.1 (1 / 10).\
Note that this is far more dramatic a computation than is usually used with large datasets (more common is 1 / log(DF)), but we need a dramatic value to see differences with a small dataset.\
Next, update your prediction formula to do a three-way dot product: document vector * profile * IDF (fortunately, SUMPRODUCT can handle a third array). If you did this right, you\'92ll see a prediction of about 0.2476 for user1/doc1.\
Ok, now let\'92s look at the results.\
Type in the answers to the following questions into the Quiz:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl320\sa200\partightenfactor0
\ls4\ilvl0\cf2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Compare doc1 and doc9 for user1. What\'92s user1\'92s prediction for doc9 in the new IDF weighted model? See how there\'92s a dramatic difference from the prior model?\cb1 \
\ls4\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Now let\'92s look at user 2. Look at doc6. It was moderately positive before and now is slightly negative. Why did that change?\cb1 \
}